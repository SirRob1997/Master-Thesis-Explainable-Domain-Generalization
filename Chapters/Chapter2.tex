\newcommand*{\eg}{e.g.\@\xspace}
\newcommand*{\ie}{i.e.\@\xspace}
\newcommand*{\cf}{cf.\@\xspace}
\newcommand{\amsbound}{\textsc{AMSBound}\xspace}
\newcommand{\adabound}{\textsc{AdaBound}\xspace}
\newcommand{\adam}{\textsc{Adam}\xspace}
\newcommand{\momentum}{\textsc{Momentum}\xspace}
\newcommand{\sgd}{\textsc{SGD}\xspace}
\newcommand{\rmsprop}{\textsc{RMSProp}\xspace}
\newcommand{\amsgrad}{\textsc{AMSGrad}\xspace}
\newcommand{\adadelta}{\textsc{Adadelta}\xspace}
\newcommand{\nag}{\textsc{NAG}\xspace}
\newcommand{\nadam}{\textsc{Nadam}\xspace}
\newcommand{\radam}{\textsc{Radam}\xspace}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}


\chapter{Domain Generalization} % Main chapter title
\label{DomainGeneralization} 

Machine learning systems often lack \emph{out-of-distribution generalization} which causes models to heavily rely on the distribution provided by the training data and as a result don't perform very well when presented with irregular qualities during testing. For example, this can be seen in application scenarios where intelligent systems don't generalize well across health centers if the training data was collected in a single hospital \citep{Castro_2020, AlBadawy2018, PeroneBBC19} or when self-driving cars struggle under alternative lighting or weather conditions \citep{DaiG18, VolkMBH019}. Often, properties which are falsely interpreted as part of the relevant feature set include backgrounds \citep{BeeryHP18}, textures \citep{GeirhosRMBWB19}, or racial biases \citep{StockC18}. Due to the prevalence of this task for the wide-spread deployment of machine learning systems in flexible environments, many researchers in the last decade tried to tackle this task with various approaches. In this chapter, we want to give a broad overview over the literature in \emph{domain generalization} and prepare the fundamentals for the following chapters. If you are already familiar with the field you can safely skip this part.

\section{Problem formulation}
\label{sec:domain_gen_problem}

In supervised learning we are aiming to optimize the predictions $\mathbf{\hat{y}}$ for the values $\mathbf{y} \in \mathcal{Y}$ of a random variable $Y$, when presented with values $\mathbf{x} \in \mathcal{X}$ of a random variable $X$. These predictions are generated with a model predictor $f(\cdot;\boldsymbol{\theta}): \mathcal{X} \rightarrow \mathcal{Y}$ that is parameterized by parameters $\boldsymbol{\theta} \in \Theta$  and is assigning the predictions as $\mathbf{\hat{y}}=f(\cdot;\boldsymbol{\theta})$. To improve our predictions, we utilize a training dataset containing $n$ input-output pairs denoted as $D=\left\{\left(\mathbf{x}_{i}, \mathbf{y}_{i}\right)\right\}_{i=1}^{n}$ where each sample $(\mathbf{x}_i,\mathbf{y}_i)$ is ideally drawn identically and independently distributed (i.i.d.) from a single joint probability distribution $P(X,Y)$. By using a loss term $\mathcal{L} (\mathbf{\hat{y}};\mathbf{y}): \mathcal{Y} \times \mathcal{Y} \rightarrow \mathbb{R}^{+}$, which quantifies how different the prediction $\mathbf{\hat{y}}$ is from the ground truth $\mathbf{y}$, we would like to minimize the risk $R(f) = \mathbb{E}_{(\mathbf{x}, \mathbf{y}) \sim P}[\mathcal{L}(f(\mathbf{x}; \boldsymbol{\theta}), \mathbf{y})]$ of our model. Since we only have access to the distribution $P(X,Y)$ through a proxy in the form of the dataset $D$, we are instead minimizing the empirical risk $R_{\mathrm{emp}}(f)=\frac{1}{n} \sum_{i=1}^n \mathcal{L}\left(f\left(\mathbf{x}_{i};\boldsymbol{\theta}\right), \mathbf{y}_{i}\right)$ by adding up the loss terms of each sample. One common choice for this is the Mean square error (MSE) which is shown in \Cref{eq:mse}. The occurring minimization problem is then often solved through iterative gradient based optimization algorithms \eg \sgd{} \citep{Robbins1951} or \adam \citep{Kingma2015} which perform reasonably well for the non-convex, continuous loss surfaces produced by modern machine learning problems.
\begin{equation}
\label{eq:mse}
    \text{MSE}=\frac{1}{n} \sum_{i=1}^n (\mathbf{y}_i-f\left(\mathbf{x}_{i};\boldsymbol{\theta}\right))^{2} = \frac{1}{n}\norm{ \mathbf{y}-f\left(\mathbf{x};\boldsymbol{\theta}\right)}_2^2
\end{equation}
On top of that, the model predictor $f$ can be decomposed into two functions as $f=w \circ \phi$ where $\phi: \mathcal{X} \rightarrow \mathcal{Z}$ is an embedding into a feature space, hence sometimes called the feature extractor, and $w: \mathcal{Z} \rightarrow \mathcal{Y}$ which is sometimes called the classifier since it is a prediction from the feature space to the output space \citep{gulrajani2020search, MotiianPAD17}. This allows for a more concise mathematical notation.

The problem of \emph{Domain generalization} builds on top of this framework, where now we have a set of training domains $\mathcal{S} = \left\{\mathcal{D}_{1}, \ldots, \mathcal{D}_{d_{\mathrm{tr}}}\right\}$ with $d \in\left\{1, \ldots, d_{\mathrm{tr}}\right\}$, where each $d$-th domain $\mathcal{D}_d$ has a dataset $D^{d}=\left\{\left(\mathbf{x}_{i}^{d}, \mathbf{y}_{i}^{d}\right)\right\}_{i=1}^{n_{d}}$ containing $n_d$ i.i.d. samples from individual distributions $P\left(X^{d}, Y^{d}\right)$. Here, $\mathbf{x}_i^d$ is the $i$-th sample for domain $\mathcal{D}_d$ and $\mathbf{y}_i^d \in\{1,2, \ldots, c\}$ is the corresponding class label \citep{wang2020learning}. From these domains, we try to learn generic feature representations agnostic to domain changes to improve model performance \citep{seo2019learning}. Simply, we try to do \emph{out-of-distribution generalization} where our model aims to achieve good performance for an unseen test domain $d_{\mathrm{te}}=d_{\mathrm{tr}}+1$ based on statistical invariances across the observed training (source) and testing (target) domains \citep{gulrajani2020search, huang2020selfchallenging}. Hence, we try to minimize the expected target risk of our model as shown in \Cref{eq:domain_risk}.
\begin{equation}
\label{eq:domain_risk}
    R(f) = \mathbb{E}_{(\mathbf{x}^{d_{\mathrm{te}}}, \mathbf{y}^{d_{\mathrm{te}}}) \sim P}[\mathcal{L}(f(\mathbf{x}^{d_{\mathrm{te}}}; \boldsymbol{\theta}), \mathbf{y}^{d_{\mathrm{te}}})]
\end{equation}
One simple approach is to apply the empirical risk minimization seen previously to the domain generalization task as shown in \Cref{eq:domain_risk_emp}, where we hope that minimizing the empirical risk over all source domains in $\mathcal{S}$ achieves good generalization to the target domain.
\begin{equation}
\label{eq:domain_risk_emp}
    R_\mathrm{emp}(f) = \frac{1}{d_\mathrm{tr}} \sum_{d=1}^{d_\mathrm{tr}} \frac{1}{n_d} \sum_{i=1}^{n_d} \mathcal{L}(f(\mathbf{x}_i^{d}; \boldsymbol{\theta}), \mathbf{y}_i^{d})
\end{equation}
The difference of this approach when compared to ordinary supervised learning is summarized on a high-level in \Cref{tab:learning_setups}. 


\begin{table}[t]
    \centering
    \begin{tabular}{lll}
    \toprule
    \textbf{Setup} & \textbf{Training inputs}  & \textbf{Testing inputs} \\
    \midrule
        Generative learning & $U^1$ & $\emptyset$ \\ 
        Unsupervised learning & $U^1$ & $U^1$  \\ 
        Supervised learning & $L^1$ & $U^1$ \\ 
        Semi-supervised learning & $L^{1}, U^{1}$ & $U^1$ \\ 
        Multitask learning & $L^{1}, \ldots, L^{d_{\mathrm{tr}}}$ & $U^{1}, \ldots, U^{d_{\mathrm{tr}}}$ \\ 
        Continual (lifelong) learning & $L^{1}, \ldots, L^{\infty}$ & $U^{1}, \ldots, U^{\infty}$ \\ 
        Domain adaption & $L^{1}, \ldots, L^{d_{\mathrm{tr}}}, U^{d_{\mathrm{tr}}+1}$ & $U^{d_{\mathrm{tr}}+1}$ \\ 
        Transfer learning & $U^{1}, \ldots, U^{d_{\mathrm{tr}}}, L^{d_{\mathrm{tr}}+1}$ & $U^{d_{\mathrm{tr}}+1}$ \\ 
        \textbf{Domain generalization} & $L^{1}, \ldots, L^{d_{\mathrm{tr}}}$ & $U^{d_{\mathrm{tr}}+1}$ \\ 
    \bottomrule
    \end{tabular}
    \caption[Differences in learning setups]{Differences in learning setups adapted from \citet{gulrajani2020search}. For each domain $d$ the labeled and unlabeled distributions are denoted as $L^d$ and $U^d$ respectively.}
    \label{tab:learning_setups}
\end{table}

There exist subtle differences within this task which are called \emph{single-} or \emph{multi-source domain generalization}. While multi-source domain generalization refers to the standard setting we have just outlined, single-source domain generalization is a more generic formulation \citep{zunino2020explainable}. Instead of relying on multiple training domains to learn models which generalize better, single-source domain generalization aims at learning these representations with access to only one source distribution. Hence, our training domains are restricted to $\mathcal{S} = \left\{\mathcal{D}_{1}\right\}$ with $d \in\left\{1\right\}$, described by one dataset $D^{1}=\left\{\left(\mathbf{x}_{i}^{1}, \mathbf{y}_{i}^{1}\right)\right\}_{i=1}^{n_{1}}$ and modeling a single source distribution $P\left(X^{1}, Y^{1}\right)$. This is different from the ordinary supervised learning setup since we want to analyze the performance of the model under a clear domain-shift (\ie out-of-distribution generalization). Note, that strong regularization methods will also perform well on this scenario. These cross-overs and related techniques are described in the following section.

\section{Related concepts and their differences}

Members of the causality community might know the task of domain generalization under the term \emph{learning from multiple environments} \citep{arjovsky2019invariant, gulrajani2020search, PetBuhMei15}. While these two concepts refer to the same task, there exist quite a few related techniques which we want to highlight here and distinguish in their scope. In particular, we focus on ``Generic neural network regularization'' and ``Domain Adaption'' since these are very closely related and sometimes hard to distinguish if at all. The overview in \Cref{tab:learning_setups}, however, includes even more learning setups to properly position this concept into the machine learning landscape.

\subsection{Generic Neural Network Regularization}

In theory, generic model regularization which aims to prevent neural networks from overfitting on the source domain, could also improve the domain generalization performance \citep{huang2020selfchallenging}. As such, methods like dropout \citep{SrivastavaHKSS14}, early stopping \citep{CaruanaLG00}, or weight decay \citep{NowlanH92} can have a positive effect on this task when deployed properly. Apart from regular dropout, where we randomly disable neurons in the training phase to stop them from co-adapting too much, a few alternative methods exist. These include dropping random  patches of input images (Cutout \& HaS) \citep{devries2017improved, SinghL17} or channels of the feature map (SpatialDropout) \citep{TompsonGJLB15}, dropping contiguous regions of the feature maps (DropBlock) \citep{GhiasiLL18}, dropping features of high activations across feature maps and channels (MaxDrop) \citep{ParkK16}, or generalizing the traditional dropout of single units to entire layers during training (DropPath) \citep{LarssonMS17}. There even exist methods like curriculum dropout \citep{MorerioCVVM17} which deploy scheduling for the dropout probability and therefore softly increase the amount of units to be suppressed layerwise during training. 

Generally, deploying some of these methods when aiming for out-of-distribution generalization can be a good idea and should definitely be considered for the task of domain generalization.


\subsection{Domain Adaption}

\emph{Domain adaption} is often mentioned as a closely related task in domain generalization literature \citep{MotiianPAD17, VolpiM19, QiaoZP20}. When compared, domain adaption has additional access to an unlabeled dataset from the target domain \citep{mancini2020, Csurka17}. Formally, aside from the set of source domains $\mathcal{S}$ and the domain datasets $D^d$, as outline in \Cref{sec:domain_gen_problem}, we have access to target samples $\mathcal{T} = \left\{\mathbf{x}_{1}^{d_\mathrm{te}},\dots,\mathbf{x}_{n_{d_{\mathrm{te}}}}^{d_\mathrm{te}}\right\}$ that are from the target domain $\mathbf{x}_j^{d_{ \mathrm{te}}} \sim P(X^{d_{ \mathrm{te}}},Y^{d_{ \mathrm{te}}})$ but their labels remain unknown in training since we want to predict them during testing. As a result, domain generalization is considered to be the harder problem of the two. This difference is also shown in \Cref{tab:learning_setups}.

Earlier methods in this space deploy hand-crafted features to reduce the difference between the source and the target domains \citep{ManciniPBC018}. Like that, \emph{instance-based methods} try to re-weight source samples according to target similarity \citep{GongGS13, HuangSGBS06, YamadaSR12} or \emph{feature-based methods} try to learn a common subspace \citep{FernandoHST13, GongSSG12, LongD0SGY13, BaktashmotlaghHLS13}. More recent works focus on \emph{deep domain adaption} based on deep architectures where domain invariant features are learned utilizing supervised neural networks \citep{BousmalisTSKE16, CarlucciPCRB17, GaninL15, GhifaryKZBL16}, autoencoders \citep{ZengOWW14}, or generative adversarial networks (GANs) \citep{BousmalisSDEK17, ShrivastavaPTSW17, TzengHSD17}. These deep neural network based architectures significantly outperform the approaches for hand-crafted features \citep{ManciniPBC018}.

Even though domain adaptation and domain generalization both try to reducing dataset bias, they are not compatible to each other \citep{GhifaryBKZ17}. Hence, domain adaptation methods often cannot be directly used for domain generalization or vice versa \citep{GhifaryBKZ17}. For this work, we don't rely on the simplifying assumptions of domain adaption, but instead tackle the more challenging task of domain generalization.

\section{Related Work}

No idea where to fit these yet: 

\citep{VolpiM19} 
\citep{QiaoZP20}
\citep{MatsuuraH20}
\citep{yao2019adversarial}
\citep{bellot2020generalization}
\citep{jin2020feature}
\citep{somavarapu2020frustratingly}
\citep{deng2020representation}
\citep{mahajan2020domain}
\citep{ilse2019diva}
\citep{arjovsky2019invariant}

Autoencoder based Methods
\citep{LiPWK18}





Deep Neural Network based Methods
\citep{seo2019learning}
\citep{wang2020learning}
\citep{du2020learning}
\citep{huang2020selfchallenging}
\citep{zhou2020learning}
\citep{Jia_2020_CVPR_SSDG}
\citep{LiZYLSH19}
\citep{CarlucciDBCT19}
\citep{LiTGLLZT18}
\citep{DingF18}
\citep{MotiianPAD17}
\citep{LiYSH17}
\citep{piratla2020efficient}
\citep{RyuK0L20}
\citep{RahmanFBS20}
\citep{ShankarPCCJS18}


Metric Learning based Methods
\citep{FangXR13}


Support vector machine based Methods
\citep{NiuLXC18}
\citep{XuLNX14}

Since literature in the domain generalization space is very broad, we utilized Appendix A in \citet{gulrajani2020search} for an overview and individually added additional works and information where necessary.  

\subsection{Learning invariant features}

Some of the earliest works on learning invariant features were \emph{kernel methods} applied by \citet{MuandetBS13}  where they look for a feature transformation that minimizes the across-domain dissimilarity between transformed feature distributions while preserving the functional relationship between original features and targets. In recent years, there have been approaches following a similar kernel based approach \citep{Hu0CC19, LiGTLT18, GhifaryBKZ17}, sometimes tackling domain adaption and domain generalization at the same time.

After that, \citet{GaninUAGLLML16} introduced Domain Adversarial Neural Networks (DANNs) utilizing neural network architectures to learn domain-invariant feature representations by adding a gradient reversal layer. Recently, their approach got extended to support statistical dependence between domains and class labels \citep{AkuzawaIM19} or considering one-versus-all adversaries to minimize pairwise divergences between source distributions \citep{albuquerque2019generalizing}. 

\subsection{Sharing parameters}

The first work to pose the problem of domain generalization and analyze it was \citet{BlanchardLS11}. They  \citep{an2019generalization} \citep{blanchard2017domain}

\citep{KhoslaZMET12} \citep{GhifaryKZB15}

\subsection{Meta-learning}
\citet{LiYSH18} propose a Model-Agnostic Meta-Learning (MAML) algorithm which is able to quickly learn new tasks. \citet{FinnAL17} adapt this algorithm for domain generalization such that we can quickly adapt to new domains by utilizing the meta-optimization objective which ensures that steps to improve training domain performance should also improve testing domain performance. Both approaches are not bound to a specific architecture and can therefore be deployed for a wide variety of learning tasks. These approaches recently got extended by two regularizers that encourage general knowledge about inter-class relationships and domain-independent class-specific cohesion \citep{DouCKG19}, to instances of domain generalization where the label space varies from domain to domain \citep{LiYZH19}, or meta-learning a regularizer which encourages across-domain performance \citep{BalajiSC18}.

\subsection{Data Augmentation}
\emph{Data Augmentation} remains a competitive method for generalizing to unseen domains \citep{zhang2019unseen}. However, to deploy an efficient procedure for that, human experts need to consider the data at hand to develop a useful routine \citep{gulrajani2020search}. Several works have used the \textsc{mixup} \citep{ZhangCDL18} algorithm as a method to merge samples from different domains \citep{XuZNLWTZ20, yan2020improve, WangLK20, mancini2020}. Other works have also tried removing textural information from images \citep{WangHLX19} or shifting it more towards shapes \citep{nam2019reducing, asadi2019shape}. \citet{CarlucciDBCT19} used jigsaw puzzles of image patches as a classification task to show that this improves domain generalization while \citet{VolpiNSDMS18} demonstrate that adversarial data augmentation on a single domain is sufficient. Several methods also utilize GANs to augment the available training data  \citep{RahmanFBS19, ZhouYHX20}.

\section{Common Datasets}

\subsection{Office-Home}
\citet{VenkateswaraECP17}

\subsection{VLCS}

(V) \citet{EveringhamGWWZ10} (L) \citet{RussellTMF08} (C) \citet{Griffin2007Caltech256OC} (S) \citet{ChoiLTW10}

\subsection{PACS}
\citet{LiYSH17}

\subsection{ImageNet-Sketch}
\citet{WangGLX19}


\subsection{ImageNet-C}
\citet{HendrycksD19}

\subsection{ImageNet-R}
\citet{hendrycks2020faces}








